---
title: Spatial anlysis of drug crime
author: Nate Day
date: '2017-12-18'
categories:
  - Cville Open Data
tags:
  - geocode
  - sf
  - spatial
description: Using library(sf) to visualize the spatial distribution of drug related
  crimes in Chalotteville
slug: drug-crime-analysis-with-library-sf
---

## Intro

Historically working with spatial data in `R` revolved around using `library(sp)`and its special `S4` classes, like "SpatialPolygonsDataFrame". The biggest reason I am excited to transition to `library(sf)` is its new `sf` objects, which are extended dataframes with a specialized list column for storing spatial geometries as simple features. This reimagined data structure means using with my favorite `tidyverse` tools on `sf` objects are now just one little `%>%` away. 

All of the data used here is originally sourced from the [Charlottesville Open Data Portal](http://opendata.charlottesville.org/). A geocoded version of the Police Reports is discussed in an earlier post and is available as a csv on [my Github repo here](https://github.com/NathanCDay/cville_crime). If you like this stuff, I'm helping with a Smart Cville Crime Data Deep Dive event on February 7th, and you should totally come.

```{r setup, include=TRUE, warning = FALSE, message = FALSE}
# the library ---------------------------------------------------------------
library(sf) # tools for simple features
library(geojsonio) # API access
library(viridis) # pretty colors
library(leaflet) # ineteractive maps
library(cowplot) # grid ggplots
library(tidyverse) # always
library(magrittr) # %<>% life

theme_set(theme_void() +
              theme(panel.grid = element_blank()))
```

## Data In

The first piece of data we need is the geo-coded version of the police reports dataset that Google Maps and I made in [my last post](/posts/drug-crime-analysis-with-library-sf.html). You can download the csv file locally or use the `raw.githubusercontent.com` domain to download directly via URL from Github.

```{r data_crime, cache = TRUE, warning = FALSE, message = FALSE}
crime <- read_csv("https://raw.githubusercontent.com/NathanCDay/cville_crime/master/crime_geocode.csv")

crime %<>% filter(complete.cases(crime)) # not all of the records could be geo-coded

names(crime) %<>% tolower() # easy typing
```

In case you missed the last post, geo-coding and manual data entry are both messy businesses. Not every address in the police reports can be accurately geocoded, but in the name of transparency my geo-coded version retains these missed locations to match the original. 

The second data piece we need is the [2010 US Census Block Group Areas](http://opendata.charlottesville.org/datasets/us-census-block-group-area-2010) for Charlottesville, Virginia, to filter the crime report locations to keep only those within the city limits. I am using `library(geojsonio)` to grab this data directly from the [ODP's API](/posts.).

```{r data_census, cache = TRUE, warning = FALSE, message = FALSE}
census <- geojson_read("https://opendata.arcgis.com/datasets/e60c072dbb734454a849d21d3814cc5a_14.geojson",
                       what = "sp") # a Spatial object (list)

census %<>% st_as_sf() # convert to sf

names(census) %<>% tolower()

census %<>% select(objectid, area = area_, population, geometry) # keep only a few variables
```

In spatial analysis, coordinate referense systems (CRS) are critical when working with multiple data sources. It is required that the CRS values match to perform any sort of spatial computations between objects. Since `census` was downloaded as geoJSON data, it already has a CRS assigned. We will use that for the setting the CRS of `crime`.

```{r crs, warning = FALSE, message = FALSE}
crs_val <- st_crs(census, asText = TRUE) # returns CRS as chr

crime %<>% st_as_sf(coords = c("lon", "lat"), # define coordinate variables
                    crs = crs_val) # set CRS to match census
```

## Spatial viz

Maybe the second biggest reason to be excited about `library(sf)` is `geom_sf()`, which is in the development version of `library(ggplot2)`. This special geom is designed specifically for plotting `sf` objects, duh, meaning now we can stay in the land of layers and coninue avoiding `plot()` like the plauge.

Because plotting ~31,000 points is a lot to plot, let's look at the data for unique addresses only, which brings us down to ~3,000 points. Remember the addresses in this dataset are only reported to the hundred block level, so we expect to have a lot reports from high frequency blocks.

```{r viz_check, fig}
# install dev ggplot2
library(devtools)
install_github("tidyverse/devtools")

ggplot(census) +
    geom_sf(data = group_by(crime, address) %>% slice(1), # only unique addresses
            alpha = .1) +
    geom_sf(color = "red", fill = NA)
```

We can see that bulk of the police reports are located within the city limits, but a lot are located just outside in Albemarle County and some reports are far far away. To focus on the crime patterns within the city we want to drop the point outside of the red areas. 

## Spatial fitler

We will use the areas from `census` as overlays to check which `crime` points fall within each, via `st_within()`. We want to store the resulting census block id for each observation in `crime` and drop the observations that don't overlap. Since this is all with `sf` objects, we can use good the good old `library(dplyr)` functions `mutate()` and `filter()`, to make it happen.

```{r filter_crime, warning = FALSE, message = FALSE}
# add a new column to show which census block group each point resides in
crime %<>% mutate(within = st_within(crime, census) %>% # returns a list by default
                      as.numeric()) # convert to numeric for mutate()

nrow(crime) # 31888
# remove rows with NAs, because they're outside of the city
crime %<>% filter(!is.na(within))
nrow(crime) # 31034

# re-viz
ggplot(census) +
    geom_sf(data = group_by(crime, address) %>% slice(1), # only unique addresses
            alpha = .1) +
    geom_sf(color = "red", fill = NA)
```

That looks better, doesn't it? And we only lost ~800 reports.

Now that we have only the police reports from within the city, let's take a closer look at the distribution of drug related crime.

## Where are the drugs?

In a perfect world all of the drug offenses would have the same tag in `crime$offense`. But this isn't DisneyLand so lets use some `grepl()` to sift out the possible related tags.

```{r plot_size, warning = FALSE, message = FALSE }
# flag drug-related offense tags
crime %<>% mutate(drug_flag = ifelse(grepl("drug", offense, ignore.case = TRUE),
                                     "drugs", "not_drugs"))

# check the "drug-related" tags
filter(crime, drug_flag == "drugs") %>% with(table(offense))
```

Those offense tags all seem to be drug related, except "DRUG AWARENESS PRESENTATION", which doesn't sound like a criminal report at all. Remember manual data entry is messy business, so let's just drop the lone "DRUG AWARENESS PRESENTATION" observation and compare the distribution of drug crime and other crime.

Here again we will use some classic `tidyverse` verbs directly on `crime`, to construct a summary of total counts for each `drug_flag` at every address. 

```{r address_sum, warning = FALSE, message = FALSE}
address_summary <- group_by(crime, address) %>%
    summarise(drug_crime = sum(drug_flag == "drugs"),
              other_crime = sum(drug_flag != "drugs")) %>%
    gather(type, number, contains("crime"))

# now plot it
ggplot(census) +
    geom_sf() +
    geom_sf(data = address_summary,
            aes(size = number, color = number, alpha = number)) +
    scale_color_viridis() +
    scale_size_area(max_size = 10) +
    facet_grid(~type)
```

It looks like there is a concentration of crime in the downtown area, which makes sense since becasue crime rates are typically proportional to population/business density. However one address downtown stands out as much more frequent that the rest, let's investigate what's going on there.

```{r}
arrange(address_summary, -number) %>% head() # 600 E Market St
```

Something is going on there. I don't think it's a coicidence, that the police station is located at 606 E Market St  Perhaps it has something to do with the departments reporting practices, but I really doubt most crimes are being commited a stone's throw from the popo.

Perhaps we can learn something more by looking at the proportion of crimes reported at 600 E Market for each type of `drug_flag`.

```{r}
station_props <- arrange(address_summary, -number) %>%
    group_by(type) %>%
    add_count(wt = number) %>%
    slice(1)

summarise(station_props, prop_total = number / n)

with(station_props, prop.test(number, n))
```

The relative proportion of drug crime reported at the police station is much higher than that for other crimes. It's quite possible that I've been watching to many crime/justice documentaries on Netflix, but I really hope there is solid reason for this disproportinate hotspot, and it's not something more. Going forward I'll drop the reports from 600 E Market so they don't cloud our anlysis.

## Hot blocks

Crime tends to cluster and typically in the most urban areas, i.e. the places with the densest populations and the densest targets. Often just a single address or block is responsible for the majority of crime reported, this is called a "hot spot". Becasue of this patternm, simply using total counts to find areas of of high criminal acivity, is not particularly useful.

So we need a normalization factor. Normalizing to the total number of crimes reported will let us calculate the proportion of drug crime, which is a more useful measuring stick.  

```{r}
# drop the police station to look at spatial trends in the community
crime %<>% filter(address != "600 E MARKET ST Charlottesville VA")

# summarise counts by census block
crime_sum <- st_set_geometry(crime, NULL) %>% # need to remove geometry property
    group_by(within, drug_flag) %>%
    count() %>%
    spread(drug_flag, n) %>% rowwise() %>%
    mutate(total = sum(drugs, not_drugs),
           frac_drugs = drugs / total)

# join rate info into census
census %<>% inner_join(crime_sum, by = c("objectid" = "within"))
```

Now that we have our count data summarrized, let's plot it, three different ways. Looking at the number of total crime crime reports, total drug crime reports and the fraction of drug crime reports in each census block group:

```{r census_heat, fig}
plot_list <- list()

plot_list[["total"]] <- ggplot(census) +
    geom_sf(aes(fill = total)) +
    scale_fill_viridis()

plot_list[["drugs"]] <- ggplot(census) +
    geom_sf(aes(fill = drugs)) +
    scale_fill_viridis()

plot_list[["frac"]] <- ggplot(census) +
    geom_sf(aes(fill = frac_drugs)) +
    scale_fill_viridis()

cowplot::plot_grid(cowplot::plot_grid(plotlist = plot_list[1:2]), plot_list[[3]], nrow = 2)
```

The total reports and total drug reports plots show similar stories, with the downtown mall area being the most frequent census block for reports. You can see how totals aren't the most useful metric.

Once we plot the fraction of drug crimes, we see a new pattern. Two census block groups where almost 10% of the crime is drug related. In order to get a better idea of what streets are included in each census block, we can replot the last "frac_drugs" plot as an interactive `leaflet` map, so we can zoom in and to get a better view.

```{r}
library(leaflet)

fill_pal <- pal <- colorNumeric("viridis", domain = census$frac_drugs)

leaflet(census, options = leafletOptions(minZoom = 12, max_zoom = 16)) %>%
    addProviderTiles("CartoDB.Positron") %>%
    addPolygons(color = ~fill_pal(frac_drugs), fillOpacity = .5,
                popup = ~paste0("drugs: ", drugs, "<br>",
                                "total: ", total)) %>%
    widgetframe::frameWidget(height = '400') # containerizes widgets so CSS properties don't interfer with page CSS
```

The two hot census blocks, are located along Cherry Avenue and 5th Street SW, just south of downtown. These adjacent areas are home to two of Charlottesville's largest Section 9 housing developments and are likely some of the lowest income areas of the city.

I have a follow up post planned for using [American Community Survey data](https://www.census.gov/programs-surveys/acs/) to expand on this idea and actualy get data to quanitfy this hypothesis that low-income area have more drug crime. Exploring quanifiable risk factors is key to using data to creating safer communities.

## Hot grid

Suppose we want to get an idea of hot spots on a smaller scale. Instead of using the census block areas, we can construct a grid of our own, with `st_make_grid()`.  The masking/point inclusion process is the same, just with new shapes. First let's make out grid and overlay it on top of the census areas

```{r make_grid, message - FALSE}
grd <- st_make_grid(census, n = 25) %>% st_sf() # 25x25 evenly sized squares

ggplot(census) +
    geom_sf(color = "red") +
    geom_sf(data = grd, fill = NA) +
    coord_sf(crs = st_crs(census), datum = NA) # remove grid lines
```

Boom done.

The inital grid fills the entire bounding box, i.e. the smallest rectangle that encompases the entire census map. This makes for a lot of grid squares that won't have any data. Let's remove the squares, whose area doesn't intersect with the area of the census blocks.

```{r,}
grd %<>% st_intersection(st_geometry(st_union(census))) # filter to those in census

ggplot(census) +
    geom_sf(color = "red") +
    geom_sf(data = grd, fill = NA) +
    coord_sf(crs = st_crs(census), datum = NA) # remove grid lines
```

The helper functions for pairwise geometry comparisons, like `st_within()` and `st_intersection()` are another nice perk of a `libary(sf)` workflow. Instead of multiple lines with `library(sp)` now it's just one!

All that's left now is to caluculate the number of points within each square, and summarise them by drug related and total reports just like we did before.

```{r grd_sum, message = FALSE}
crime$grd <- st_within(crime, grd) %>% as.numeric()

grd_sum <- st_set_geometry(crime, NULL) %>% # need to remove geometry property
    group_by(grd, drug_flag) %>%
    count() %>%
    spread(drug_flag, n) %>% rowwise() %>%
    mutate(drugs = ifelse(is.na(drugs), 0, drugs), # some areas don't have drug related crime, recode from NA to 0
           total = sum(drugs, not_drugs, na.rm = TRUE),
           frac_drugs = drugs / total)

# join sumamry stats back into grd
grd %<>% set_names("geometry") %>% # sf functions look for geometry column
    mutate(grd = 1:nrow(.)) %>% # make a key to match back on
    full_join(grd_sum)
```

We did a little extra processing here than earlier, because as we moved to smaller summary areas, we introduced some areas without data (no crime reports). To imporove our visualiation, we recoded the ares with no drug crime from missing values to zeros. The area wihtout any crime reported are still treated as NAs.

```{r leaf_frac}
bins <- c(0, .05, .1, .15, 1) # set custom bin breaks
grd_pal <- pal <- colorBin("viridis", domain = grd$frac_drugs, bins = bins) # important to rescale

leaflet(grd, options = leafletOptions(minZoom = 12, max_zoom = 16)) %>%
    addProviderTiles("CartoDB.Positron") %>%
    addPolygons(data = census, fill = NA, color = "black", weight = 1) %>%
    addPolygons(color = ~grd_pal(frac_drugs), stroke = FALSE, fillOpacity = .75,
                popup = ~paste0("drugs: ", drugs, "<br>",
                                "total: ", total)) %>%
    addLegend(pal = grd_pal, values = ~frac_drugs, opacity = .7, title = NULL,
              position = "bottomright", na.label = "no crimes") %>%
    widgetframe::frameWidget(height = '400')
```

Clicking on a given grid square will show the break down of crimes reported there. We can see several of the highlighted hot spots have very low numbers of total reports, making their fraction of drug related offenses much higher. Still we see a band of blue and green squares to the south-west of downtown, in the same hot census blocks. 

Now that we are looking at smaller areas, let's remake the plot above but instead of using the fraction of drug related crime, go back to using just total drug reports to see where the highest volume areas are.

```{r leaf_drugs}
bins2 <- c(0, 10, 25, 50, Inf)
grd_pal2 <- colorBin("viridis", domain = grd$drugs, bins = bins2)

leaflet(grd, options = leafletOptions(minZoom = 12, max_zoom = 16)) %>%
    addProviderTiles("CartoDB.Positron") %>%
    addPolygons(data = census, fill = NA, color = "black", weight = 1) %>%
    addPolygons(color = ~grd_pal2(drugs), stroke = FALSE, fillOpacity = .75,
                popup = ~paste0("drugs: ", drugs, "<br>",
                                "total: ", total)) %>%
    addLegend(pal = grd_pal2, values = ~frac_drugs, opacity = .7, title = NULL,
              position = "bottomright", na.label = "no crimes") %>%
    widgetframe::frameWidget(height = '400')
```

Using totals instead, highlights the hottest (yellow) spots as around the downtown mall. Other noteable hotter spots (green) cover areas near IX and Tonsler parks, both of those have large numbers of total reports. The lone green grid on the north side of the city, covers Charlottesville High School and no residental streets. There were 25 drug crimes reported there among 306 total crimes, making it one of the most frequent spots for criminal activity. Charlottesville's reputatation for public school to prison pipeline, might have some data to back it up.

## Wrap up

I hope this was a easy to follow use case for spatial anlysis with `library(sf)`. I think it make a lot of the spatial manipulation simpler than before and it plays nicely with the `tidyverse`. It's integration isn't seemless yet, there are still some friction points, but I am excited to see it mature. 

If you liked this sort of stuff, come out to the Smart Cville meetup in February and get your hands coding. If you have any feedback on this project or other ideas where data might be able to help Cville, let me know. Cheers!

