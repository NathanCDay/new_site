---
title: Geocoded crime reports for Charlottesville Virginia
author: Nate Day
date: '2018-11-27'
slug: geocoded-crime-reports-for-charlottesville-virginia
twitter_img: "post/2018-11-18-geocoded-crime-reports-for-charlottesville-virginia_files/cpdcrimedata_twittercard.png"
categories:
  - Civic Data
tags:
  - packages
  - sf
  - tidyverse
---

## cpdcrimedata

Is a R data package, with a geocoded version of the [Charlottesville Police Department's public Assistant Reports](http://opendata.charlottesville.org/datasets/crime-data) for the last five years.

To install the package from [GitHub](https://github.com/nathancday/cpdcrimedata):

```{r install, message = F}
devtools::install_github("nathancday/cpdcrimedata")

library(cpdcrimedata)

library(tidyverse) # for manipulation tools
```

The primary dataset is `cpd_crime`, the [original report's](http://opendata.charlottesville.org/datasets/crime-data) 9 columns (UpperCamel), plus 4 new ones (lower_snake) related to geocoding:

* `formatted_address` - address used in the successful GoogleAPI query
* `lat` - lattitude value returned
* `lon` - longitude value returned
* `loc_type` - type of location returned

```{r}
data(cpd_crime)

names(cpd_crime)

map(cpd_crime, ~ table(.) %>% sort(decreasing = T) %>% head)
```

The original data is left untouched.

It has all of the orignal warts and wrinkles and you will likely need to a little extra data cleaning. The `Offense` column has a lot of variants for similar labels.

```{r}
cpd_crime$Offense %>%
  keep(~ grepl("larceny", ., ignore.case = T)) %>%
  table()
```


### Making a plot

Let's look at 6 most frequent offense labels we saw up above, with `ggplot2`.

```{r explore, message = F}
library(tidyverse)

topn <- cpd_crime %>%
  mutate(Offense = fct_infreq(Offense)) %>%
  filter(Offense %in% levels(Offense)[1:6])
```

By design this dataset contains all of the records in the original, including records were not able to be geocoded. Several addresses were geocoded as outside of the city limits and some are very far away! 

To see the spatial distribution of police reports in the city, these "bad" records need to go. Here I'm using [US Census maps from the CODP](), as the geographic mask to keep only the locations in the city.

```{r spatial_join, message = F, warning = F}
library(sf)

# get a census map of charlottesville
cville_census <- st_read("https://opendata.arcgis.com/datasets/63f965c73ddf46429befe1132f7f06e2_15.geojson") %>%
  select(Tract)

topn <- topn %>% 
  filter_at(vars(lat, lon), all_vars(!is.na(.))) %>%
  st_as_sf(coords = c("lon", "lat"), crs = st_crs(cville_census)) %>%
  st_join(cville_census, left = F)
```

Now we can plot with `ggplot2/sf`. Since `geom_sf()` can be prohibitably slow with ~9000 data points, I'm using a work-around with `stat_bin_2d`.

```{r plot}
# add the coordinates as a data frame s for ggplot()
topn <- st_coordinates(topn) %>% 
  as_tibble() %>%
  setNames(c("lon","lat")) %>%
  bind_cols(topn)

# stat_bin() is a good alt geom
ggplot(cville_census) +
  geom_sf() +
  stat_density_2d(data = topn, aes(lon, lat, fill = stat(level)),
                  alpha = .5, geom = "polygon") +
  scale_fill_viridis_c(option = "A", name = "# reports") +
  coord_sf(datum = NA) +
  facet_wrap(~Offense) +
  theme_void()
```

## Going forward

Having this dataset as a R package is making my life easier. It was a good learning experiance for me to put this thing together and I pushed myself to get it set up on for CI with Travis! I'm looking forward to keeping this dataset 

Intereseted in converting other Charlottesville data into R packages (possibly one big meta-package) to make civic data analysis with #rstats more accessible/shareable? If you have ideas for other local datasets that could benefit from a package tune-up, send me an email or [open an issue](https://github.com/nathancday/cpdcrimedata/issues)
