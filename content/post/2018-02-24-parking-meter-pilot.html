---
title: Parking Meter Pilot
description: A vizual introductuion to stats and trends of the city's cancelled Downtown mall parking meter program.
author: Nate Day
date: '2018-02-24'
slug: parking-meter-pilot
categories:
  - R
  - EDA
  - Cville Open Data
tags:
  - data wrangling
  - dates
  - time series
  - tidyverse
---

<script src="/rmarkdown-libs/htmlwidgets/htmlwidgets.js"></script>
<script src="/rmarkdown-libs/jquery/jquery.min.js"></script>
<link href="/rmarkdown-libs/leaflet/leaflet.css" rel="stylesheet" />
<script src="/rmarkdown-libs/leaflet/leaflet.js"></script>
<link href="/rmarkdown-libs/leafletfix/leafletfix.css" rel="stylesheet" />
<link href="/rmarkdown-libs/leaflet-label/leaflet.label.css" rel="stylesheet" />
<script src="/rmarkdown-libs/leaflet-label/leaflet.label.js"></script>
<script src="/rmarkdown-libs/Proj4Leaflet/proj4-compressed.js"></script>
<script src="/rmarkdown-libs/Proj4Leaflet/proj4leaflet.js"></script>
<script src="/rmarkdown-libs/leaflet-binding/leaflet.js"></script>
<script src="/rmarkdown-libs/leaflet-providers/leaflet-providers.js"></script>
<script src="/rmarkdown-libs/leaflet-providers-plugin/leaflet-providers-plugin.js"></script>


<div id="intro" class="section level2">
<h2>Intro</h2>
<p>The Charlottesville City Council <a href="http://www.nbc29.com/story/37183074/charlottesville-ends-parking-meter-pilot-program">voted to not resume</a> the Downtown parking lot pilot as scheduled on January 2, 2018 and now <a href="http://opendata.charlottesville.org/datasets/parking-meter-pilot-data">the data</a> is on the City’s Open Data Portal. This program began last year on September 5th with <a href="http://www.nbc29.com/story/37153548/charlottesville-to-restart-parking-meter-program">105 on street spots</a> around the Downtown mall. It took a holiday break starting mid November and was supposed to resume in 2018 and run until March 5th.</p>
<p>The city’s numbers show they collected $51,000, despite the abbreviated study, but this is likely not enough to cover <a href="http://www.nbc29.com/story/37201791/charlottesville-unlikely-to-see-profit-from-parking-meters">remaining expenses</a> like repairing vandalism and paying the survey designers. This makes the premature end to the pilot program, mildly disturbing, why would the city want to shoot itself in the foot and take a loss when the numbers showed a strong successful start.</p>
<p>The original aim of the meters was to improve short term parking access by getting longer term parkers to use the parking decks more. Downtown business owners have had concerns about the <a href="http://www.nbc29.com/story/36032734/charlottesville-officials-host-meeting-on-metered-parking-pilot-program">negative impact</a> these meters might have on their livelihoods from the beinging.</p>
<p>I want to see if there are any trends in this data that support the business concern or the decision to end the program early.</p>
</div>
<div id="packages" class="section level2">
<h2>Packages</h2>
<pre class="r"><code>library(geojsonio) # get ODP data
library(leaflet) # maps
library(viridis) # colors
library(ggsci) # more colors
library(magrittr) # %&lt;&gt;% is great for cleaner code
library(lubridate) # tidyverse time date fxns; doesn&#39;t auto-load tho
library(tidyverse) # yep</code></pre>
</div>
<div id="data-in" class="section level2">
<h2>Data In</h2>
<p>There are two “Parking Meter” data two links on the ODP, <a href="http://opendata.charlottesville.org/datasets/parking-meter-pilot-data">“Pilot Data” (everything)</a> and “Pilot Locations” (subset with only lat/lon cordinates). So we need “Pilot Data” to explore revenue trends and patterns, which is ~27,000 rows (5.1 MB). I like <a href="/2017/10/01/codp-api/">using the GeoJSON API with <code>geojsonio</code></a> to pull data from the portal, but you could just as easily download the CSV file and use <code>read.table()</code> instead.</p>
<pre class="r"><code>dat &lt;- geojson_read(&quot;https://opendata.arcgis.com/datasets/d68e620e74e74ec1bd0184971e82ffaa_15.geojson&quot;,
                    parse = TRUE) %&gt;%
    .[[&quot;features&quot;]] %&gt;%
    .[[2]]

str(dat)</code></pre>
<pre><code>&#39;data.frame&#39;:   27968 obs. of  18 variables:
 $ RecordID         : int  1 2 3 4 5 6 7 8 9 10 ...
 $ Bills            : int  0 0 0 0 0 0 0 0 0 0 ...
 $ Card             : num  0 1.8 2.1 3.6 1.8 3.6 2.7 1.8 1.8 3.6 ...
 $ Coins            : num  0 0 0 0 0 0 0 0 0 0 ...
 $ Date_Payment     : chr  &quot;2017/09/15 00:00:00+00&quot; &quot;2017/09/15 00:00:00+00&quot; &quot;2017/09/15 00:00:00+00&quot; &quot;2017/09/15 00:00:00+00&quot; ...
 $ InvalidCoins     : chr  &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; ...
 $ LicensePlateAnon : chr  &quot;8532&quot; &quot;7086&quot; &quot;3669&quot; &quot;5625&quot; ...
 $ Meter_Lat        : num  38 38 38 38 38 ...
 $ Meter_Long       : num  -78.5 -78.5 -78.5 -78.5 -78.5 ...
 $ MeterType        : chr  &quot;Multispace&quot; &quot;Multispace&quot; &quot;Multispace&quot; &quot;Multispace&quot; ...
 $ ParkingEndTime   : chr  &quot;09/15/2017 02:36:11 PM&quot; &quot;09/15/2017 03:32:19 PM&quot; &quot;09/15/2017 03:40:58 PM&quot; &quot;09/15/2017 03:53:25 PM&quot; ...
 $ SpaceName        : chr  &quot;MS12&quot; &quot;MS12&quot; &quot;MS12&quot; &quot;MS12&quot; ...
 $ Time_Payment     : chr  &quot;02:36:11&quot; &quot;02:32:19&quot; &quot;02:30:58&quot; &quot;01:53:25&quot; ...
 $ TimePurchased    : chr  &quot;00:00:00&quot; &quot;01:00:00&quot; &quot;01:10:00&quot; &quot;02:00:00&quot; ...
 $ Total            : num  0 1.8 2.1 3.6 1.8 3.6 2.7 1.8 1.8 3.6 ...
 $ TotalParkingTime : chr  &quot;00:00:00&quot; &quot;01:00:00&quot; &quot;01:10:00&quot; &quot;02:00:00&quot; ...
 $ TransactionStatus: chr  &quot;&quot; &quot;Approved&quot; &quot;Approved&quot; &quot;Approved&quot; ...
 $ TransactionType  : chr  &quot;Credit Card&quot; &quot;Credit Card&quot; &quot;Credit Card&quot; &quot;Credit Card&quot; ...</code></pre>
<pre class="r"><code>names(dat) %&lt;&gt;% tolower() # I just think lower-case is easier to type</code></pre>
<p>Just from the column names we can see the data has everything we need to investigate the temporal patterns in usage and revenue, but because all of the columns are either <code>character</code> or <code>numeric</code>, we need to do some cleaning first.</p>
<p>In order to really explore this data set properly, we need to build some <code>POSIXct</code> class columns for date and time. Since there are multiple columns describing time and date, I choose to just use “ParkingEndTime” as the starting material for consistancy.</p>
<p>And now back to our regularly scheduled <code>POSIXct</code> conversion. That’s how exploratory data analysis works in the wild, it’s always a good idea to keep any eye out for <code>NA</code>s in any raw data set.</p>
<pre class="r"><code># split column into date, clock:time, AM/PM parts
tmp &lt;- strsplit(dat$parkingendtime, &quot; &quot;)

# get dates
dat$date &lt;- map_chr(tmp, ~.[1]) %&gt;%
    as.POSIXct(format = &quot;%m/%d/%Y&quot;)

# get times
dat$time &lt;- map_chr(tmp, ~.[2]) %&gt;% # get clock:time from each 2nd slot
    as.POSIXct(format = &quot;%H:%M:%S&quot;)

# convert to 24hr clock
pm_add &lt;- ifelse(grepl(&quot;PM&quot;, dat$parkingendtime) &amp; !grepl(&quot; 12:&quot;, dat$time), #
                 43200, # 12 hours = 43200 seconds
                 0)
dat$time %&lt;&gt;% add(pm_add)</code></pre>
<p>Now we have the columns we need to get started visualizing.</p>
</div>
<div id="explore" class="section level2">
<h2>Explore</h2>
<p>Let’s start by looking at the time-course of usage of all the meters for duration of the program. I think it makes sense to use weeks as the grouping varaible and <code>lubridate::isoweek</code> makes it easy to calculate the week number from begining of the year.</p>
<pre class="r"><code>dat$week &lt;- isoweek(dat$date) %&gt;% as.factor()

ggplot(dat, aes(week)) +
    geom_bar()</code></pre>
<p><img src="/post/2018-02-24-parking-meter-pilot_files/figure-html/week_counts-1.png" width="672" /></p>
<p>Here we are looking at just the counts of meter transactions and we can see constant usage over the course of the program data. The first and last weeks, #36 and #46 are missing days, so they appear lower than average.</p>
<p>Before we go future we need to find out where those NA values came from.</p>
<div id="na-investigation" class="section level4">
<h4>NA investigation</h4>
<p><code>NA</code>s are nice in data exploration, I like to think of them as data mining’s equivalent to the <a href="https://en.wiktionary.org/wiki/canary_in_a_coal_mine">carnary in a coal mine.</a>, because they alert you to missing or (more often) missed data.</p>
<pre class="r"><code>filter(dat, is.na(week)) %&gt;% head(5)</code></pre>
<pre><code>  recordid bills card  coins           date_payment invalidcoins
1      452     0    0 -36.10 2017/09/26 00:00:00+00            0
2      525     0    0 -33.95 2017/09/14 00:00:00+00            0
3      591     0    0 -12.15 2017/11/16 00:00:00+00            0
4      630     0    0 -33.40 2017/11/09 00:00:00+00            0
5      686     0    0 -27.55 2017/11/02 00:00:00+00            0
  licenseplateanon meter_lat meter_long   metertype parkingendtime
1              N/A  38.03142    -78.481 Singlespace           &lt;NA&gt;
2              N/A  38.03142    -78.481 Singlespace           &lt;NA&gt;
3              N/A  38.03142    -78.481 Singlespace           &lt;NA&gt;
4              N/A  38.03142    -78.481 Singlespace           &lt;NA&gt;
5              N/A  38.03142    -78.481 Singlespace           &lt;NA&gt;
  spacename time_payment timepurchased  total totalparkingtime
1      0S1E     08:36:21          &lt;NA&gt; -36.10             &lt;NA&gt;
2      0S1E     09:07:28          &lt;NA&gt; -33.95             &lt;NA&gt;
3       S1W     07:33:44          &lt;NA&gt; -12.15             &lt;NA&gt;
4       S1W     06:53:11          &lt;NA&gt; -33.40             &lt;NA&gt;
5       S1W     07:08:59          &lt;NA&gt; -27.55             &lt;NA&gt;
  transactionstatus transactiontype date time week
1                     Collect. Card &lt;NA&gt; &lt;NA&gt; &lt;NA&gt;
2                     Collect. Card &lt;NA&gt; &lt;NA&gt; &lt;NA&gt;
3                     Collect. Card &lt;NA&gt; &lt;NA&gt; &lt;NA&gt;
4                     Collect. Card &lt;NA&gt; &lt;NA&gt; &lt;NA&gt;
5                     Collect. Card &lt;NA&gt; &lt;NA&gt; &lt;NA&gt;</code></pre>
<p>Here I used <code>head()</code> for breviety in the markdown but in RStudio I could use <code>View()</code> instead.</p>
<p>Looks like all of these transactions are the same type “Collect. Card” and all of them are negative balance transactions occuring at midnight. But let’s be sure.</p>
<pre class="r"><code>filter(dat, is.na(week)) %&gt;% with(table(transactiontype)) # yep all of them</code></pre>
<pre><code>transactiontype
Collect. Card 
          241 </code></pre>
<pre class="r"><code>filter(dat, is.na(week)) %&gt;% with(range(total)) # all negative or zero</code></pre>
<pre><code>[1] -255.65    0.00</code></pre>
<pre class="r"><code>filter(dat, is.na(parkingendtime)) %&gt;% with(mean(total)) # average of -$31</code></pre>
<pre><code>[1] -31.61888</code></pre>
<p>I’m not 100% what these “Collect. Card” transactions represent, but I’m guessing they are batched credit card transactions. Not sure why they would be included in the data set, but going with my gut instinct, I want to drop them going forward.</p>
<pre class="r"><code>dat %&lt;&gt;% filter(transactiontype != &quot;Collect. Card&quot;)</code></pre>
<p>This is a great example of oddities in raw data and why it pays to pay attention to the details. Never trust in raw data, always confirm things are what you expect and use <code>NA</code> values a clues to look deeper.</p>
</div>
<div id="weekly-revenue" class="section level4">
<h4>Weekly revenue</h4>
<p>Now that the missing values are removed, we want to look at the actual revenue, because let’s face it 💰 talks.</p>
<pre class="r"><code>week_rev &lt;- group_by(dat, week) %&gt;%
    summarise(revenue = sum(total)) %&gt;%
    slice(c(-1, -n())) # drop first &amp; last week

ggplot(week_rev, aes(week, revenue)) +
    geom_col()</code></pre>
<p><img src="/post/2018-02-24-parking-meter-pilot_files/figure-html/week_rev-1.png" width="672" /></p>
<p>Remember local business owners were worried about the meters reducing traffic to their establishments. While we don’t have the business records (that’d be cool), we don’t see a decreasing pattern in usage or revenue from the metered spots. It looks like people continued using the spaces and the Downtown mall businesses, dispite the increased cost.</p>
<p>Next let’s look at what a typical meter fee was. The <code>total</code> column has this data in it.</p>
<pre class="r"><code>mean(dat$total) # average fee</code></pre>
<pre><code>[1] 1.855765</code></pre>
<pre class="r"><code>hist(dat$total) # distribution of fees</code></pre>
<p><img src="/post/2018-02-24-parking-meter-pilot_files/figure-html/avg_fee-1.png" width="672" /></p>
<pre class="r"><code>sum(dat$total) # total revenue</code></pre>
<pre><code>[1] 51454.79</code></pre>
<p>So the average meter bill was just under $2 and people rarely paid over $4. Most of the acitivities found on the Downtown mall from shows to restraunts are going to cost a little more than $2, so this small fee wasn’t a deal breaker for people looking to park conviently. And sure the meters collected more than $50,000 dollars in 9 weeks! That’s a lot of 💸 and means the meters have already payed for themselves.</p>
</div>
<div id="average-week" class="section level4">
<h4>Average Week</h4>
<p>If our haunches are corrected and people are coming to the Downtown mall for food or fun, that’s what I do. We would expect meter traffic to increase at lunch, dinner and on the weekends. First lets look at which days are busiest with <code>lubridate::wday()</code>.</p>
<pre class="r"><code>dat$day &lt;- wday(dat$date, T)

ggplot(dat, aes(day)) +
    geom_bar()</code></pre>
<p><img src="/post/2018-02-24-parking-meter-pilot_files/figure-html/day_of_week-1.png" width="672" /></p>
<pre class="r"><code># no one usese meters on Sundays.
dat %&lt;&gt;% filter(day != &quot;Sun&quot;)</code></pre>
<p>That was just the counts, but hardly anyone uses the meters on Sunday. Let’s look at revenue.</p>
<pre class="r"><code>rev_by_day &lt;- group_by(dat, day) %&gt;% 
    summarise(revenue = sum(total))

ggplot(rev_by_day, aes(day, revenue)) +
    geom_col()</code></pre>
<p><img src="/post/2018-02-24-parking-meter-pilot_files/figure-html/rev_by_day-1.png" width="672" /></p>
<p>Ok so Sunday becomes even less relevant, but we see a stronger signal of increased weekend usage. Saturday is the largest earner, followed by Friday then Thursday. Looks when people are going to the mall for weekend recreation they don’t mind using the metered spots.</p>
</div>
<div id="average-day" class="section level4">
<h4>Average Day</h4>
<p>To look for time of day patterns in meter usage Let’s use <code>lubridate::hour()</code> to extract the hour from our <code>POSIXct</code> times.</p>
<pre class="r"><code>dat$hour &lt;- hour(dat$time)

ggplot(dat, aes(hour)) +
    geom_bar() +
    scale_x_continuous(breaks = c(8,12,17,20), labels = c(&quot;8a&quot;, &quot;12p&quot;, &quot;5p&quot;, &quot;8p&quot;))</code></pre>
<p><img src="/post/2018-02-24-parking-meter-pilot_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>We can see an increase in meter activity at lunch time and a big spike at 8pm. The meter spots only required feeding between 8am - 8pm, but it looks like they are only catching the begining of the evening traffic to the downtown mall. I wonder if the meters would capture a lot more revenue if the program was extended until 10p or even 12a?</p>
<p>Let’s check the revenue numbers for each hour.</p>
<pre class="r"><code>group_by(dat, hour) %&gt;%
    summarise(rev = sum(total)) %&gt;%
    ggplot(aes(hour, rev)) +
    geom_col() +
    scale_x_continuous(breaks = c(8,12,17,20), labels = c(&quot;8a&quot;, &quot;12p&quot;, &quot;5p&quot;, &quot;8p&quot;))</code></pre>
<p><img src="/post/2018-02-24-parking-meter-pilot_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>The revenue numbers show the 8pm spike is bigger than the counts indicated. Extending the metered hours to cover more of peak evening mall activity looks like an even better idea. The 8p-10p window would likely produce some high revenue numbers, assuming the evening rush has a similar pattern to the lunch time one.</p>
</div>
<div id="different-days" class="section level4">
<h4>Different days</h4>
<p>We might expect that the evening spike is largest on the weekends, because most people don’t hit the bars early in the week, and that the lunch time peak is sharpest during the work week, when people are on tighter schedules.</p>
<p>To get a better idea, we can take advantage of <code>hour</code> and <code>day</code> to group on.</p>
<pre class="r"><code># look at hour and day
group_by(dat, hour, day) %&gt;%
    summarise(revenue = sum(total)) %&gt;%
    ggplot(aes(hour, revenue, colour = day, group = day)) +
    geom_path(size = 1.5) +
    scale_color_d3()  +
    scale_x_continuous(breaks = c(8,12,17,20), labels = c(&quot;8a&quot;, &quot;12p&quot;, &quot;5p&quot;, &quot;8p&quot;))</code></pre>
<p><img src="/post/2018-02-24-parking-meter-pilot_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>This is great because we can see the evening meter revnue spike happen every single day, but the biggest spikes belong to Saturday, Friday, and Thursday like we expected.</p>
<p>We also see more a lot more traffic at lunch on Friday than other days and who doesn’t like a nice Friday office escape to enjoy a tasty lunch.</p>
<p>I think the spike on Monday at 5p is interesting, perhaps it’s people hitting happy hour to help soothe their case of the Mondays?</p>
</div>
<div id="money-meters" class="section level4">
<h4>Money meters</h4>
<p>This pilot included 100+ metered spaces around the downtown mall, and this data set identifies spaces by their <code>spacename</code>, of which there are 41. Each of these represents either one or multiple spaces and that info is stored in <code>metertype</code>. Unfortunatly there is no data indicating how many spaces belong to a given meter 😞. So we need to be careful when looking for high revenue meters, to make sure we aren’t just identifying the meters with the most spaces.</p>
<pre class="r"><code>space_rev &lt;- group_by(dat, spacename, metertype) %&gt;%
    summarise(revenue = sum(total))

ggplot(space_rev, aes(spacename, revenue)) +
    geom_col() +
    facet_grid(~metertype, scales = &quot;free_x&quot;, space = &quot;free_x&quot;) +
    theme(axis.text.x = element_text(angle = 90, vjust = .5)) # to be able to read it</code></pre>
<p><img src="/post/2018-02-24-parking-meter-pilot_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>We have a lot more single space meters than multi-space ones and sure enough multi-space meters generate more revenue, who woulda’ though?</p>
<p>The <code>spacename</code>s don’t tell me anything useful about the location of the spaces, but remember this data set comes with lat/lon coordinates for each meter. Let’s look at a map of the meters to see where the busiest ones were located. I’m going to use color to show <code>log2(revenue)</code> and stroke (size of outline) to show <code>metertype</code>. Transforming to a log2 scale helps normalize <code>dist(revenue)</code> and prevent the multispace meters from soaking up most of our color range.</p>
<pre class="r"><code>space_rev &lt;- group_by(dat, spacename, metertype, meter_lat, meter_long) %&gt;%
    summarise(revenue = sum(total))

pal &lt;- colorNumeric(
    palette = &quot;viridis&quot;,
    domain = log2(space_rev$revenue))

leaflet(space_rev) %&gt;%
    addProviderTiles(&quot;OpenStreetMap.BlackAndWhite&quot;) %&gt;%
    addCircleMarkers(lat= ~meter_lat, lng= ~meter_long,
                     color = ~pal(log2(revenue)),
                     radius = ~ifelse(metertype == &quot;Singlespace&quot;, 10, 20)) %&gt;%
    addLegend(&quot;bottomright&quot;, pal = pal, values = ~log2(revenue),
              labFormat = labelFormat(transform = function(x) 2^x),
              title = &quot;$USD Revenue&quot;)</code></pre>
<div id="htmlwidget-1" style="width:672px;height:480px;" class="leaflet html-widget"></div>
<script type="application/json" data-for="htmlwidget-1">{"x":{"options":{"crs":{"crsClass":"L.CRS.EPSG3857","code":null,"proj4def":null,"projectedBounds":null,"options":{}}},"calls":[{"method":"addProviderTiles","args":["OpenStreetMap.BlackAndWhite",null,null,{"errorTileUrl":"","noWrap":false,"zIndex":null,"unloadInvisibleTiles":null,"updateWhenIdle":null,"detectRetina":false,"reuseTiles":false}]},{"method":"addCircleMarkers","args":[[38.0310585073,38.031417896,38.0317432882,38.0304714737,38.0305602683,38.0299253212,38.0296302148,38.0292608726,38.0305036852,38.0305042319,38.031085742,38.0312242603,38.0309090295,38.031041946,38.0305856902,38.0306341914,38.030750841,38.030320864,38.0312604409,38.0313709607,38.0320655626,38.0319975466,38.0319483313,38.0314196044,38.0317843302,38.0317857007,38.0302244086,38.0302254607,38.0297757062,38.029773419,38.0294497359,38.0294507964,38.0294958683,38.0294968712,38.0295173744,38.0295156061,38.0293240358,38.0293245166,38.0292709545,38.029271861,38.029259843],[-78.4804771702,-78.4809987599,-78.4820682361,-78.4824494573,-78.4824137444,-78.480139178,-78.4795044178,-78.4787312264,-78.4775994664,-78.4776008063,-78.4799798597,-78.47992865,-78.479368165,-78.4793181883,-78.4790594546,-78.4785267437,-78.4784198491,-78.4770569598,-78.4813115186,-78.4820215237,-78.48294608,-78.4833500019,-78.4834566361,-78.4810016063,-78.4821992623,-78.482201404,-78.4821894901,-78.4821919825,-78.4802075252,-78.4802086992,-78.4797540822,-78.4797574736,-78.4798991408,-78.4799026504,-78.4795561444,-78.4795569468,-78.4793557963,-78.4793575076,-78.4791901988,-78.4791920802,-78.478732039],[10,10,10,10,10,10,10,10,10,10,20,20,20,20,20,20,20,20,20,20,20,20,20,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10],null,null,{"lineCap":null,"lineJoin":null,"clickable":true,"pointerEvents":null,"className":"","stroke":true,"color":["#33628D","#1E9C89","#22A884","#26818E","#228B8D","#287C8E","#25838E","#25848E","#20A486","#1F9E89","#A7DB34","#E2E418","#95D840","#E5E419","#A2DA37","#94D840","#D1E11C","#AADC32","#43BF70","#70CF57","#E9E51A","#EFE51C","#FDE725","#1F9E89","#20A486","#1FA187","#20938C","#21908D","#277E8E","#23898E","#27808E","#2C728E","#1E9B8A","#1F998A","#23888E","#2A768E","#1F9A8A","#3D4D8A","#1F968B","#218E8D","#440154"],"weight":5,"opacity":0.5,"fill":true,"fillColor":["#33628D","#1E9C89","#22A884","#26818E","#228B8D","#287C8E","#25838E","#25848E","#20A486","#1F9E89","#A7DB34","#E2E418","#95D840","#E5E419","#A2DA37","#94D840","#D1E11C","#AADC32","#43BF70","#70CF57","#E9E51A","#EFE51C","#FDE725","#1F9E89","#20A486","#1FA187","#20938C","#21908D","#277E8E","#23898E","#27808E","#2C728E","#1E9B8A","#1F998A","#23888E","#2A768E","#1F9A8A","#3D4D8A","#1F968B","#218E8D","#440154"],"fillOpacity":0.2,"dashArray":null},null,null,null,null,null,null,null]},{"method":"addLegend","args":[{"colors":["#440154 , #472C7A 12.1660813073591%, #355F8D 29.718764060225%, #238A8D 47.2714468130909%, #2EB37C 64.8241295659567%, #89D548 82.3768123188226%, #FDE725 99.9294950716885%, #FDE725 "],"labels":["128","256","512","1,024","2,048","4,096"],"na_color":null,"na_label":"NA","opacity":0.5,"position":"bottomright","type":"numeric","title":"$USD Revenue","extra":{"p_1":0.121660813073591,"p_n":0.999294950716884},"layerId":null,"className":"info legend"}]}],"limits":{"lat":[38.029259843,38.0320655626],"lng":[-78.4834566361,-78.4770569598]}},"evals":[],"jsHooks":[]}</script>
<p>We see the multi-space meters along Market Street make the most money. But is it really just because the have more spaces? While we don’t have actual sub-space counts, we can do an approximation, assuming the number of sub-spaces is the same for each multi-space meter. Remember this program launched with 105 spaces.</p>
<p>Note: I’m not using the <code>log2</code> transformation anymore, since the values are well distributed in linear space.</p>
<pre class="r"><code>table(space_rev$metertype)</code></pre>
<pre><code>
 Multispace Singlespace 
         13          28 </code></pre>
<pre class="r"><code>avg_spaces &lt;- (105 - 28) / 13

space_rev %&lt;&gt;% mutate(avg_space_revnue = ifelse(metertype == &quot;Singlespace&quot;,
                                                 revenue,
                                                 revenue / avg_spaces))
pal &lt;- colorNumeric(
    palette = &quot;viridis&quot;,
    domain = space_rev$avg_space_revnue)

leaflet(space_rev) %&gt;%
    addProviderTiles(&quot;OpenStreetMap.BlackAndWhite&quot;) %&gt;%
    addCircleMarkers(lat= ~meter_lat, lng= ~meter_long,
                     color = ~pal(avg_space_revnue),
                     radius = ~ifelse(metertype == &quot;Singlespace&quot;, 10, 20)) %&gt;%
    addLegend(&quot;bottomright&quot;, pal = pal, values = ~avg_space_revnue,
              title = &quot;$USD Revenue&quot;)</code></pre>
<div id="htmlwidget-2" style="width:672px;height:480px;" class="leaflet html-widget"></div>
<script type="application/json" data-for="htmlwidget-2">{"x":{"options":{"crs":{"crsClass":"L.CRS.EPSG3857","code":null,"proj4def":null,"projectedBounds":null,"options":{}}},"calls":[{"method":"addProviderTiles","args":["OpenStreetMap.BlackAndWhite",null,null,{"errorTileUrl":"","noWrap":false,"zIndex":null,"unloadInvisibleTiles":null,"updateWhenIdle":null,"detectRetina":false,"reuseTiles":false}]},{"method":"addCircleMarkers","args":[[38.0310585073,38.031417896,38.0317432882,38.0304714737,38.0305602683,38.0299253212,38.0296302148,38.0292608726,38.0305036852,38.0305042319,38.031085742,38.0312242603,38.0309090295,38.031041946,38.0305856902,38.0306341914,38.030750841,38.030320864,38.0312604409,38.0313709607,38.0320655626,38.0319975466,38.0319483313,38.0314196044,38.0317843302,38.0317857007,38.0302244086,38.0302254607,38.0297757062,38.029773419,38.0294497359,38.0294507964,38.0294958683,38.0294968712,38.0295173744,38.0295156061,38.0293240358,38.0293245166,38.0292709545,38.029271861,38.029259843],[-78.4804771702,-78.4809987599,-78.4820682361,-78.4824494573,-78.4824137444,-78.480139178,-78.4795044178,-78.4787312264,-78.4775994664,-78.4776008063,-78.4799798597,-78.47992865,-78.479368165,-78.4793181883,-78.4790594546,-78.4785267437,-78.4784198491,-78.4770569598,-78.4813115186,-78.4820215237,-78.48294608,-78.4833500019,-78.4834566361,-78.4810016063,-78.4821992623,-78.482201404,-78.4821894901,-78.4821919825,-78.4802075252,-78.4802086992,-78.4797540822,-78.4797574736,-78.4798991408,-78.4799026504,-78.4795561444,-78.4795569468,-78.4793557963,-78.4793575076,-78.4791901988,-78.4791920802,-78.478732039],[10,10,10,10,10,10,10,10,10,10,20,20,20,20,20,20,20,20,20,20,20,20,20,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10],null,null,{"lineCap":null,"lineJoin":null,"clickable":true,"pointerEvents":null,"className":"","stroke":true,"color":["#3B518B","#76D054","#FDE725","#23898E","#1FA187","#277E8E","#21908D","#20928C","#D2E21B","#8CD646","#26818E","#31B57B","#2C738E","#35B779","#287D8E","#2C738E","#20A386","#25838E","#443B84","#375A8C","#3DBC74","#4BC16D","#77D153","#8AD647","#CBE11F","#B0DD2F","#3BBB75","#28AE80","#26828E","#1E9D89","#24868E","#2E6D8E","#6DCD59","#62CB5F","#1E9B8A","#2C738E","#6ACD5B","#453581","#48C16E","#25AB82","#440154"],"weight":5,"opacity":0.5,"fill":true,"fillColor":["#3B518B","#76D054","#FDE725","#23898E","#1FA187","#277E8E","#21908D","#20928C","#D2E21B","#8CD646","#26818E","#31B57B","#2C738E","#35B779","#287D8E","#2C738E","#20A386","#25838E","#443B84","#375A8C","#3DBC74","#4BC16D","#77D153","#8AD647","#CBE11F","#B0DD2F","#3BBB75","#28AE80","#26828E","#1E9D89","#24868E","#2E6D8E","#6DCD59","#62CB5F","#1E9B8A","#2C738E","#6ACD5B","#453581","#48C16E","#25AB82","#440154"],"fillOpacity":0.2,"dashArray":null},null,null,null,null,null,null,null]},{"method":"addLegend","args":[{"colors":["#440154 , #460B5E 2.70109055072163%, #453781 15.6683999636915%, #365C8D 28.6357093766614%, #287C8E 41.6030187896313%, #1E9B8A 54.5703282026012%, #38B977 67.5376376155711%, #7DD24F 80.504947028541%, #D3E21B 93.472256441511%, #FDE725 "],"labels":["100","200","300","400","500","600","700","800"],"na_color":null,"na_label":"NA","opacity":0.5,"position":"bottomright","type":"numeric","title":"$USD Revenue","extra":{"p_1":0.0270109055072163,"p_n":0.934722564415109},"layerId":null,"className":"info legend"}]}],"limits":{"lat":[38.029259843,38.0320655626],"lng":[-78.4834566361,-78.4770569598]}},"evals":[],"jsHooks":[]}</script>
<p>That image looks more balanced than before, we don’t see the multi-space Market St bias. Now it looks like the meters were used evenly across locations, with the two best earning spots closest to Felleni’s on the corner of Market and 2nd NW. Which makes sense, Felleni’s is awesome.</p>
</div>
</div>
<div id="conculsion" class="section level2">
<h2>Conculsion</h2>
<p>This data set shows us a lot about when people were parking at the mall meters. We see meter usage was steady across the pilot, which is counter to the concerns of businesses that the meters would decrease mall traffic. We also still see lunch, dinner and weekend spikes, indicating people don’t mind feeding a meter, if it means getting a good spot close to their destination. It would be great to get some business revenue data from the same time period, to see the other side of the story, but from here it doesn’t appear that the meters decreased traffic to the mall.</p>
<p>This data set also shows that the meters were distributed well, revenue was fairly consistant across spots. I would love to have the actual multi-space breakdown for sub-spaces, but even without that we see a story of positive cash flow. The decision to stop the program doesn’t seem to have stong data support, I would love to know what information the council had before their vote.</p>
<pre class="r"><code>mean(week_rev$revenue) * 52 # weeks</code></pre>
<pre><code>[1] 260710</code></pre>
<p>If the meter pilot was run for an entire year, without a holiday break, this data says the city would expect to collect more than $250,000 dollars! Even if the city’s annual expense to maintain the meters was half of their original cost or $25,500, that would still be a huge chunk of change avaialble to support the city’s schools or future infrastructure improvements.</p>
<p>Overall this looks like Charlottesville missed an opportunity here, and I really hope the city council understood this data before their vote.</p>
</div>
