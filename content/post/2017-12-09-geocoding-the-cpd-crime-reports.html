---
title: Geocoding the CPD crime reports
author: Nate Day
date: '2017-12-09'
categories:
  - Cville Open Data
tags:
  - data wrangling
  - geocode
  - ggmap
description: Geocoding the Charlottesville Police Dept's crime reports with Google
  Maps
slug: geocoding-the-cpd-crime-reports
---



<!-- ####![maps](/images/geocode_crime/maps.gif) -->
<div id="geocoding" class="section level2">
<h2>Geocoding</h2>
<p>‚ÄúIs the process of converting addresses (like a street address) into geographic coordinates (like latitude and longitude), which you can use to place markers on a map, or position the map.‚Äù - <a href="https://developers.google.com/maps/documentation/geocoding/start">Google Maps API Documentation</a></p>
<p>Unfortunately the Crime Data from the <a href="http://opendata.charlottesville.org/">Charllottesville Open Data Portal</a> (OPD) doesn‚Äôt come currated with latitude and longitude coordinates. So it is up to us to geocode it, by accessing the Google Maps API via the great R üì¶ <a href="https://github.com/dkahle/ggmap">ggmap</a>.</p>
<pre class="r"><code># Load Out -----------------------------------------------
library(geojsonio)
library(ggmap)
library(tidyverse) # always
library(magrittr) # %&lt;&gt;% life</code></pre>
</div>
<div id="import" class="section level2">
<h2>Import</h2>
<p>Using the OPD‚Äôs API is easy with <code>library(geojsonio)</code> and I made a separate <a href="./api.html">API post here</a>, if you want more details. I like to use <code>geojsonio::geojson_read</code> to import any data from the ODP. By default the return value will be a <code>list</code> object, in the ‚ÄúgeoJSON‚Äù format. Becasue the crime data has no geometry/shape components, we can parse the original <code>list</code> down to just a <code>tibble</code>.</p>
<pre class="r"><code>crime_json &lt;- geojson_read(&quot;https://opendata.arcgis.com/datasets/d1877e350fad45d192d233d2b2600156_7.geojson&quot;,
                           parse = TRUE) # ~ 1-5 minutes...for a 2 element list

# parse out table of interest
crime_df &lt;- crime_json[[&quot;features&quot;]]
crime_df &lt;-  crime_df[[&quot;properties&quot;]]</code></pre>
<p>We now have 31,885 crime reports in our hands.</p>
<p>This dataset contains all of the crimes reported in Charlottesville since the fall of 2012, except for homicides. I hope the homicde reports are included in the future, becasue homicides are the worst type of threat in terms of public safety and the public deserves to know.</p>
<p>Since geocoding is based exclusivley on the address of a location, we need to make sure to pay special attention to the quality of information in the <code>BlockNumber</code> and <code>StreetName</code> columns. Since this dataset it populated directly from reports, there will inevitably be some typos, but we can take a few simple steps to improve our geocoding success.</p>
<p>First lets look at <code>BlockNumber</code>. This dataset does not include specific addresses by design, in an effort to balance privacy and public safety, so all values are rounded to the nearest hundred.</p>
<pre class="r"><code># first step always trim white space
crime_df %&lt;&gt;% mutate_at(vars(BlockNumber, StreetName), funs(trimws(.)))

# convert to numeric for sorting
crime_df$BlockNumber %&lt;&gt;% as.numeric()
table(crime_df$BlockNumber, useNA = &quot;always&quot;) %&gt;% sort()</code></pre>
<pre><code>## 
##  2800  3100  3400  3800  4400  6200  6300  6500  8000  8200 10000 10800 
##     1     1     1     1     1     1     1     1     1     1     1     1 
## 11000 11100 12000 12200 14500 15000 15600 28000  2900  3300  5300  7200 
##     1     1     1     1     1     1     1     1     2     2     2     2 
##  9100  3000  &lt;NA&gt;  2600  4000  2700  2400  2500  2300  2200  2000  1700 
##     2     4    19    22    26    42   122   123   228   276   357   418 
##  2100     0  1800  1900  1300  1200  1600  1500  1000  1400  1100   900 
##   435   498   618   632   906   950   955  1047  1252  1460  1570  1685 
##   300   800   500   700   400   600   200   100 
##  1713  1722  1937  1951  1967  2265  2962  3693</code></pre>
<p>From my personal expeirence, I know that addresses for the ‚Äú0‚Äù block, like ‚Äú0 Avon St‚Äù, geocode poorly. To combat this I am recoding all reports from a zero hundred block to a one hundred block. This is small shift geographically, and since it often results in a more accurate location we are likely improving subsequent spatial analysis compared to the zero hundred block call, which is usally called somewhere near the middle of the street‚Äôs length. Also I am recoding the NA values as one hundred block values as well.</p>
<pre class="r"><code>crime_df$BlockNumber %&lt;&gt;% ifelse(is.na(.), 100, .) %&gt;% ifelse(. == 0, 100, .)
table(crime_df$BlockNumber, useNA = &quot;always&quot;) # better</code></pre>
<pre><code>## 
##   100   200   300   400   500   600   700   800   900  1000  1100  1200 
##  4210  2962  1713  1967  1937  2265  1951  1722  1685  1252  1570   950 
##  1300  1400  1500  1600  1700  1800  1900  2000  2100  2200  2300  2400 
##   906  1460  1047   955   418   618   632   357   435   276   228   122 
##  2500  2600  2700  2800  2900  3000  3100  3300  3400  3800  4000  4400 
##   123    22    42     1     2     4     1     2     1     1    26     1 
##  5300  6200  6300  6500  7200  8000  8200  9100 10000 10800 11000 11100 
##     2     1     1     1     2     1     1     2     1     1     1     1 
## 12000 12200 14500 15000 15600 28000  &lt;NA&gt; 
##     1     1     1     1     1     1     0</code></pre>
<p>Next lets look at the <code>StreetName</code> values. Here we can expect a lot more unique values and a lot more typing mistakes.</p>
<pre class="r"><code>table(crime_df$StreetName) %&gt;% sort(decreasing = TRUE) %&gt;% head(20) # don&#39;t print too much</code></pre>
<pre><code>## 
##        E MARKET ST          W MAIN ST         EMMET ST N 
##               1786               1332               1127 
##          E MAIN ST JEFFERSON PARK AVE          5TH ST SW 
##                756                714                563 
##        PRESTON AVE           RIDGE ST         CHERRY AVE 
##                560                547                527 
##       PROSPECT AVE         GARRETT ST         14TH ST NW 
##                502                480                479 
##     UNIVERSITY AVE            PARK ST        WERTLAND ST 
##                469                383                363 
##        CARLTON AVE         E WATER ST           1ST ST S 
##                352                338                336 
##           HARDY DR         W WATER ST 
##                328                309</code></pre>
<pre class="r"><code>length(table(crime_df$StreetName)) # 1704</code></pre>
<pre><code>## [1] 1691</code></pre>
<p>We see the most popular streets for crime reports are ‚ÄúE MARKET ST‚Äù, ‚ÄúMAIN ST‚Äù (both W and E) and ‚ÄúN EMMET ST‚Äù. This is not suprising since Market St and Main St are the two major East-West roads through downtown, and Emmet St is the major North-South route.</p>
<p>Since there are almost 1700 unique street names, of course we see things like ‚ÄúW MAINS T‚Äù and ‚ÄúWEST MAIN‚Äù, that are obvious typos, but because manually adjusting all of these would be tedious work and these mistaken street names represent a small fraction of the total cases, we will leave them for now. Plus leaving them in also will make it easy to merge the geocoded data back in later on.</p>
<p>The final step in our geocode prep is to append the correct ‚ÄúCity, State‚Äù. Since almost every American town has a Main St, we need to be specific that we only care about the Main St in Charlottesville Virginia. So now all that‚Äôs left to do is <code>paste</code> everything together and let Google handle the heavy lifting.</p>
<pre class="r"><code>crime_df %&lt;&gt;% mutate(address = paste(BlockNumber, StreetName, &quot;Charlottesville VA&quot;))</code></pre>
</div>
<div id="google-maps-api" class="section level2">
<h2>Google Maps API</h2>
<p>Google Maps are the best and of course Google offers some really nice APIs to work with them. This makes using Google Maps attractive to companies and because of this Google has established tiered (read $$$) access levels to these utilities. Any individual can submit 2,500 request to the API per day, for free, which is really nice. Beyond that a billing account is required and the nominal fee of $0.50 per 1,000 requests is charged. That means if we wanted to run a query for every report in the dataset we would have to wait 13 days or pay ~ $15 dollars. The fifteen dollars doesn‚Äôt sound too bad, but if we filter down to unique addresses only we can cut our costs drastically.</p>
<pre class="r"><code># check for unique addresses
address_df &lt;- data.frame(address = unique(crime_df$address))
nrow(address_df) # 3144</code></pre>
<pre><code>## [1] 3159</code></pre>
<p>Now we are down to more palatable number of 3,144 unique location, that we can break up into just two days worth of API querying and still keep it free. There is a free alternative to using Google Maps, called the Data Science Toolkit (DSK). The DSK does not impose query limit restrictions, but I think that Google does a better job. You can specify which source to use when running <code>ggmap::geocode</code> with the <code>source</code> argument, Google is the default and the one I will be using here.</p>
<pre class="r"><code>address_list &lt;- split(address_df,
                      rep(c(T,F), length.out = nrow(address_df)))

res1a &lt;- geocode(address_list[[1]]$address, source = &quot;google&quot;, output = &quot;all&quot;)
res2a &lt;- geocode(address_list[[2]]$address, source = &quot;google&quot;, output = &quot;all&quot;)</code></pre>
<pre class="r"><code>res1a &lt;- readRDS(&quot;~/future/cville_crime/res1a.RDS&quot;)
res2a &lt;- readRDS(&quot;~/future/cville_crime/res2a.RDS&quot;)</code></pre>
<p>The argument <code>output</code> defaults to ‚Äúlatlon‚Äù, which will nicely return just the lattitude and longitude coordinates. Since I wanted te be sure the geocoding was behaving itself I opted for the ‚Äúall‚Äù option, which returns a JSON nest list object with a lot more information, including the formatted address actually used by google for each query and the status of the query. The status value is useful to check and see how many address were succesfully coded.</p>
<pre class="r"><code>map_lgl(res1a, ~.[&quot;status&quot;] == &quot;OK&quot;) %&gt;% sum(na.rm = T) # 1550 / 1572
map_lgl(res2a, ~.[&quot;status&quot;] == &quot;OK&quot;) %&gt;% sum(na.rm = T) # 1551 / 1572</code></pre>
<p>Because I choose to pull all of this extra data, I need to do a little work extracting it, so I wrote a helper function to parse all of the returned JSON objects. If you want to create your own parser function, practice using <code>le &lt;- res1a[[1]]</code> until you have what you want.</p>
<pre class="r"><code>extractor &lt;- function(le) {
    if (length(le) == 2) {
        if (le$status == &quot;OK&quot;) { # so we ignore status: ZERO_RESULTS
            res &lt;- le$results %&gt;% unlist() %&gt;% bind_rows() %&gt;%
                select(lat = geometry.location.lat,
                       lon = geometry.location.lng,
                       formatted_address,
                       geometry_loc_type = geometry.location_type)
        }
    }
    else { res &lt;- tibble(formatted_address = NA) } # leave a place holder for misses
    return(unique(res))
}

res1a_parsed &lt;- map_df(res1a, extractor, .id = &quot;query&quot;)
res2a_parsed &lt;- map_df(res2a, extractor, .id = &quot;query&quot;)</code></pre>
<p>Now that I have all of those long nast JSON objects cleaned up into tidy tibbles, all I need to do it bring the two group back together again and merge with the original <code>address_df</code> we used to populate the geocoding queries.</p>
<pre class="r"><code>res &lt;- bind_rows(res1a_parsed, res2a_parsed) %&gt;% 
    full_join(address_df, ., by = c(&quot;address&quot; = &quot;query&quot;)) # on Github</code></pre>
<p>This final table with all of the unique address geocodes is available on [my GitHub here](<a href="https://github.com/NathanCDay/cville_crime/blob/master/addresses_geocode.csv" class="uri">https://github.com/NathanCDay/cville_crime/blob/master/addresses_geocode.csv</a>. I plan to periodically update this as new versions of the crime data become available, but I will checke here first, so I don‚Äôt needlessly rerun queries. Eventually this may turn into an offline geocoder for Charlottesville.</p>
<p>Becasue I like making things easy, I also have a <a href="https://github.com/NathanCDay/cville_crime/blob/master/crime_geocode.csv">full geocoded version of the Crime dataset</a> we downloaded the the ODP available here on my GitHub too. But if you want to make your own just use <code>inner_join()</code>.</p>
<pre class="r"><code>crime &lt;- inner_join(crime_df, res) # also on Github</code></pre>
<p>If you notice that my GitHub repository is out of sync with the ODP (ie my repo was last updated prior to the most recent Crime dataset update), you will want to check against the unique address table (perhaps using <code>anti_join</code> or <code>full_join</code> as a first step instead of <code>inner_join</code>) and geocode any new addresses that failed to match. Also feel free to open an issue on my GitHub repo and I will make adjustments for the updated data.</p>
</div>
